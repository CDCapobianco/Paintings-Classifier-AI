{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CDCapobianco/Paintings-Classifier-AI/blob/main/Paintings_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Kaggle Dataset**"
      ],
      "metadata": {
        "id": "5yg4YxQB_gt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq_6V1oRBMKB",
        "outputId": "478c2618-bea5-433d-dada-2051e249c70f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ~/.kaggle\n",
        "! mkdir ~/.kaggle\n",
        "!cp /content/gdrive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "I-fg9Ooi_kEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129a25ea-358b-4e2c-f135-e78dbe553f56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/root/.kaggle': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download thedownhill/art-images-drawings-painting-sculpture-engraving"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRCdsKhcAOJ1",
        "outputId": "8feaf52d-0704-4cbf-ce1c-b51d9cc41619"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading art-images-drawings-painting-sculpture-engraving.zip to /content\n",
            " 99% 578M/583M [00:19<00:00, 41.8MB/s]\n",
            "100% 583M/583M [00:19<00:00, 31.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/art-images-drawings-painting-sculpture-engraving.zip\",\"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"/content\")\n"
      ],
      "metadata": {
        "id": "ug3oLXMjCsCX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/musemart/dataset_updated/training_set /content/dataset/dataset_updated\n",
        "!cp -r /content/musemart/dataset_updated/validation_set /content/dataset/dataset_updated\n",
        "!rm -r /content/musemart"
      ],
      "metadata": {
        "id": "3VH_0EaNU-6P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/dataset/dataset_updated/training_set/drawings /content/dataset/dataset_updated\n",
        "!cp -r /content/dataset/dataset_updated/training_set/engraving /content/dataset/dataset_updated\n",
        "!cp -r /content/dataset/dataset_updated/training_set/iconography /content/dataset/dataset_updated\n",
        "!cp -r /content/dataset/dataset_updated/training_set/painting /content/dataset/dataset_updated\n",
        "!cp -r /content/dataset/dataset_updated/training_set/sculpture /content/dataset/dataset_updated"
      ],
      "metadata": {
        "id": "qG9PClSHb8UJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/dataset/dataset_updated/validation_set/drawings /content/dataset/dataset_updated\n",
        "!cp -r /content/dataset/dataset_updated/validation_set/engraving /content/dataset/dataset_updated\n",
        "!cp -r /content/dataset/dataset_updated/validation_set/iconography /content/dataset/dataset_updated\n",
        "!cp -r /content/dataset/dataset_updated/validation_set/painting /content/dataset/dataset_updated\n",
        "!cp -r /content/dataset/dataset_updated/validation_set/sculpture /content/dataset/dataset_updated"
      ],
      "metadata": {
        "id": "pphrYQ2scVdV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/dataset/dataset_updated/training_set\n",
        "!rm -r /content/dataset/dataset_updated/validation_set"
      ],
      "metadata": {
        "id": "L8IeQIMOcmqV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning**"
      ],
      "metadata": {
        "id": "l9NjganzCkKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_adamw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDJl_KGkvB8Z",
        "outputId": "6633c723-7334-4a76-d796-f9a01763e6d1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_adamw\n",
            "  Downloading keras_adamw-1.38-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_adamw) (1.21.6)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras_adamw) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (4.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (0.24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (2.8.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (1.44.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (1.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (13.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_adamw) (1.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras_adamw) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras_adamw) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras_adamw) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, keras-adamw\n",
            "Successfully installed keras-adamw-1.38 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "oB7jfhOhvgyd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES_PATH = \"/content/dataset/dataset_updated\""
      ],
      "metadata": {
        "id": "Fy4N0PNRXsy4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_files_number(path=IMAGES_PATH):\n",
        "  total = 0\n",
        "  for root,dirs,files in os.walk(path):\n",
        "    total+=len(files)\n",
        "  return total"
      ],
      "metadata": {
        "id": "iGPqqoYsW_kJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rimuoviamo le immagini corrotte\n",
        "from pathlib import Path\n",
        "import imghdr\n",
        "\n",
        "data_dir = IMAGES_PATH\n",
        "image_extensions = [\".png\", \".jpg\"]\n",
        "\n",
        "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
        "for filepath in Path(data_dir).rglob(\"*\"):\n",
        "    if filepath.suffix.lower() in image_extensions:\n",
        "        img_type = imghdr.what(filepath)\n",
        "        if img_type is None:\n",
        "            print(f\"{filepath} is not an image\")\n",
        "            os.remove(filepath)\n",
        "        elif img_type not in img_type_accepted_by_tf:\n",
        "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")\n",
        "            os.remove(filepath)"
      ],
      "metadata": {
        "id": "86pWHQhpXDYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf5bdbcd-ae7c-472f-d5ce-2b7aa0829675"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset/dataset_updated/sculpture/107.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/170.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/98.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/200.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/190 18.59.45.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/40.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/329.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/3.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/190.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/261.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/3 18.59.45.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/138.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/106.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/168.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/374.jpg is not an image\n",
            "/content/dataset/dataset_updated/sculpture/210.jpg is not an image\n",
            "/content/dataset/dataset_updated/engraving/304.jpg is not an image\n",
            "/content/dataset/dataset_updated/engraving/249.jpg is not an image\n",
            "/content/dataset/dataset_updated/engraving/356.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0075.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1125.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1050.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1775.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0475.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0225.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2075.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2150.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0850.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2125.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0200.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0125.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1750.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0975.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0650.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1450.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1975.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1875.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2200.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0625.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1425.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1025.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1475.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0025.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1950.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0800.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0750.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1150.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2275.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2025.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0575.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0775.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0350.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2000.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1900.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0525.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2300.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0275.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1850.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0900.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1300.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1225.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0550.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1675.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2350.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0400.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1925.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0450.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0375.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1825.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1375.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0000.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0300.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0950.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0825.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2325.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1700.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0875.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1350.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1725.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0325.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1250.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2100.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1600.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0925.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1100.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2175.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1525.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0500.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0050.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2050.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1800.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1550.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0675.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1275.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1075.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0725.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1200.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1000.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1575.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2250.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0425.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0175.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2050 20.26.31.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0250.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0150.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/2225.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1625.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0700.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1650.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1175.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/0600.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1400.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1325.jpg is not an image\n",
            "/content/dataset/dataset_updated/painting/1500.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/570.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/564.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/128.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/1.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/7.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/69.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/1 18.59.20.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/54.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/321.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/61.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/442.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/385.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/494.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/6.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/331.jpg is not an image\n",
            "/content/dataset/dataset_updated/iconography/188.jpg is not an image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "STEPS_PER_EPOCH = 8\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "qWvqxmKodIdb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "pTK2fjrbvsDi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TF_KERAS\"] = '1'\n",
        "from keras_adamw import AdamW\n",
        "\n",
        "\n",
        "train_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    IMAGES_PATH,\n",
        "    validation_split = 0.2,\n",
        "    subset = \"training\",\n",
        "    seed = 42,\n",
        "    image_size = (IMG_WIDTH,IMG_HEIGHT),\n",
        "    batch_size = 32\n",
        ")\n",
        "\n",
        "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    IMAGES_PATH,\n",
        "    validation_split = 0.2,\n",
        "    subset = \"validation\",\n",
        "    seed = 42,\n",
        "    image_size = (IMG_WIDTH,IMG_HEIGHT),\n",
        "    batch_size = 32\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBxgA5j5Pkmb",
        "outputId": "499a043f-ce31-480e-f2ec-2ffc9f88793c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8741 files belonging to 5 classes.\n",
            "Using 6993 files for training.\n",
            "Found 8741 files belonging to 5 classes.\n",
            "Using 1748 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = train_set.class_names"
      ],
      "metadata": {
        "id": "DTKAyXH_cycj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6i-AYyK75YY",
        "outputId": "9fdb76e8-f0cb-4f96-8944-aae312a9f05f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.BatchDataset"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataset: tf.data.Dataset, validation_data_fraction: float):\n",
        "\n",
        "    validation_data_percent = round(validation_data_fraction * 100)\n",
        "    if not (0 <= validation_data_percent <= 100):\n",
        "        raise ValueError(\"validation data fraction must be ∈ [0,1]\")\n",
        "\n",
        "    dataset = dataset.enumerate() #supponendo validation_data_fraction = 0.3 \n",
        "    train_dataset = dataset.filter(lambda f, data: f % 100 > validation_data_percent) #ogni 100 elementi, prende gli ultimi 70\n",
        "    validation_dataset = dataset.filter(lambda f, data: f % 100 <= validation_data_percent) #ogni 100 elementi, prende i primi 30\n",
        "\n",
        "    # rimuoviamo enumerazione\n",
        "    train_dataset = train_dataset.map(lambda f, data: data)\n",
        "    validation_dataset = validation_dataset.map(lambda f, data: data)\n",
        "\n",
        "    return train_dataset, validation_dataset"
      ],
      "metadata": {
        "id": "_WUmt7qP8rZY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set,test_set = split_dataset(train_set,0.2)"
      ],
      "metadata": {
        "id": "-wknZLsIOeeE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_set = train_set.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
        "validation_set = validation_set.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_set = test_set.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "tf5MMmtZbci4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training and Testing**"
      ],
      "metadata": {
        "id": "T8IK2eaZGa-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Rescaling(1./255,input_shape = [IMG_HEIGHT,IMG_WIDTH,3]),\n",
        "  tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(len(num_classes))\n",
        "])"
      ],
      "metadata": {
        "id": "c67HxAD-GdPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HjKmU82JwM9",
        "outputId": "e4f71e08-72e0-4f14-a27b-e76b9ab75b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling (Rescaling)       (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 254, 254, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 127, 127, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 127, 127, 64)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 62, 62, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 30, 30, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 57600)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               7372928   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,449,221\n",
            "Trainable params: 7,449,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Bg3KgilJIBUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learning_rate_exponential(epoch):\n",
        "  return 0.1*0.1**(epoch/20)\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(factor=0.25,patience=5)"
      ],
      "metadata": {
        "id": "oTmeTc47Jtp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=20,verbose=1)"
      ],
      "metadata": {
        "id": "2fjqvaViKDHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_set,epochs=35,validation_data=(validation_set),callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "id": "XRTDzbcaIMMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585aa22a-33ea-484b-a28c-5667caaec5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.evaluate(test_set)"
      ],
      "metadata": {
        "id": "ZdklcfsJ4SFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "for image_batch, label_batch in test_set:\n",
        "   y_true.append(label_batch)\n",
        "   preds = model.predict(image_batch)\n",
        "   y_pred.append(np.argmax(preds, axis = - 1))\n",
        "\n",
        "correct_labels = tf.concat([item for item in y_true], axis = 0)\n",
        "predicted_labels = tf.concat([item for item in y_pred], axis = 0)"
      ],
      "metadata": {
        "id": "6t7iCIZP6dit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = tf.math.confusion_matrix(correct_labels,predicted_labels)"
      ],
      "metadata": {
        "id": "QdmuItt952YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix"
      ],
      "metadata": {
        "id": "zbEbelSs606_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns \n",
        "import pandas as pd \n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "cm = pd.DataFrame(confusion_matrix.numpy(), # use .numpy(), because now confusion is tensor\n",
        "               range(5),range(5))\n",
        "\n",
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(cm, annot=True, annot_kws={\"size\": 12})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pRafJUzw7C9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transfer Learning with MobileNetV2**"
      ],
      "metadata": {
        "id": "s1dXx3LKCBAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "mnYcBssrJxSb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    IMAGES_PATH,\n",
        "    validation_split = 0.2,\n",
        "    subset = \"training\",\n",
        "    seed = 25,\n",
        "    image_size = (224,224),\n",
        "    batch_size = 32\n",
        ")\n",
        "\n",
        "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    IMAGES_PATH,\n",
        "    validation_split = 0.2,\n",
        "    subset = \"validation\",\n",
        "    seed = 25,\n",
        "    image_size = (224,224),\n",
        "    batch_size = 32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzCWGgtKGLEf",
        "outputId": "ce0dfbe0-9fa3-436a-c736-52381e6eb5f2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8741 files belonging to 5 classes.\n",
            "Using 6993 files for training.\n",
            "Found 8741 files belonging to 5 classes.\n",
            "Using 1748 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_cardinality = tf.data.experimental.cardinality(validation_set)\n",
        "test_set = validation_set.take(validation_cardinality // 5)\n",
        "validation_set = validation_set.skip(validation_cardinality // 5)"
      ],
      "metadata": {
        "id": "XNTXN2SyGbU1"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = tf.keras.applications.MobileNetV2(weights='imagenet',include_top=False,input_shape=[224,224,3])"
      ],
      "metadata": {
        "id": "eKYrQfmMCIm3"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE  = tf.data.AUTOTUNE\n",
        "\n",
        "train_set = train_set.prefetch(buffer_size = AUTOTUNE)\n",
        "test_set = test_set.prefetch(buffer_size = AUTOTUNE)\n",
        "validation_set = validation_set.prefetch(buffer_size = AUTOTUNE)"
      ],
      "metadata": {
        "id": "AV4vzIY_2gv1"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in pretrained_model.layers:\n",
        "  layer.trainable=False"
      ],
      "metadata": {
        "id": "NV6jiH1SC7fz"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_layer = tf.keras.layers.Rescaling(1./127.5,offset=-1,input_shape=[224,224,3])\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(5)\n",
        "\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = preprocessing_layer(inputs)\n",
        "x = pretrained_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dense(128,activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "FeE6niFICqKN"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(patience=2,factor=0.5,monitor=\"val_loss\")"
      ],
      "metadata": {
        "id": "Y4UKf87YDYDd"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystopping = tf.keras.callbacks.EarlyStopping(patience=5,monitor=\"val_accuracy\",verbose=1,restore_best_weights=True)"
      ],
      "metadata": {
        "id": "xBGYt6EBG3UY"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fp9QTMpFntg",
        "outputId": "f9403a98-bf97-44eb-b0ef-11cabd3be895"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_set,validation_data=(validation_set),epochs=25,callbacks=[lr_scheduler,earlystopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LILv4K9FxzK",
        "outputId": "a3a0d4b8-0a81-412c-b846-21eb58b54125"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "219/219 [==============================] - 29s 116ms/step - loss: 0.2371 - accuracy: 0.9175 - val_loss: 0.2839 - val_accuracy: 0.9076 - lr: 0.0100\n",
            "Epoch 2/25\n",
            "219/219 [==============================] - 25s 112ms/step - loss: 0.2196 - accuracy: 0.9234 - val_loss: 0.3063 - val_accuracy: 0.9119 - lr: 0.0100\n",
            "Epoch 3/25\n",
            "219/219 [==============================] - 25s 110ms/step - loss: 0.2322 - accuracy: 0.9139 - val_loss: 0.2754 - val_accuracy: 0.9191 - lr: 0.0100\n",
            "Epoch 4/25\n",
            "219/219 [==============================] - 25s 110ms/step - loss: 0.2066 - accuracy: 0.9239 - val_loss: 0.2877 - val_accuracy: 0.9205 - lr: 0.0100\n",
            "Epoch 5/25\n",
            "219/219 [==============================] - 24s 110ms/step - loss: 0.1925 - accuracy: 0.9271 - val_loss: 0.2675 - val_accuracy: 0.9133 - lr: 0.0100\n",
            "Epoch 6/25\n",
            "219/219 [==============================] - 25s 110ms/step - loss: 0.1942 - accuracy: 0.9278 - val_loss: 0.3147 - val_accuracy: 0.9040 - lr: 0.0100\n",
            "Epoch 7/25\n",
            "219/219 [==============================] - 25s 112ms/step - loss: 0.1404 - accuracy: 0.9489 - val_loss: 0.2914 - val_accuracy: 0.9305 - lr: 0.0100\n",
            "Epoch 8/25\n",
            "219/219 [==============================] - 25s 111ms/step - loss: 0.1128 - accuracy: 0.9561 - val_loss: 0.3074 - val_accuracy: 0.9298 - lr: 0.0050\n",
            "Epoch 9/25\n",
            "219/219 [==============================] - 25s 111ms/step - loss: 0.0945 - accuracy: 0.9611 - val_loss: 0.3710 - val_accuracy: 0.9262 - lr: 0.0050\n",
            "Epoch 10/25\n",
            "219/219 [==============================] - 25s 111ms/step - loss: 0.0803 - accuracy: 0.9693 - val_loss: 0.3395 - val_accuracy: 0.9269 - lr: 0.0025\n",
            "Epoch 11/25\n",
            "219/219 [==============================] - 25s 111ms/step - loss: 0.0708 - accuracy: 0.9711 - val_loss: 0.3622 - val_accuracy: 0.9248 - lr: 0.0025\n",
            "Epoch 12/25\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9770Restoring model weights from the end of the best epoch: 7.\n",
            "219/219 [==============================] - 25s 111ms/step - loss: 0.0613 - accuracy: 0.9770 - val_loss: 0.3447 - val_accuracy: 0.9291 - lr: 0.0012\n",
            "Epoch 12: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('tl_weights.h5')"
      ],
      "metadata": {
        "id": "XjXSA1aiNxnL"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_set)"
      ],
      "metadata": {
        "id": "CgHWfSdnUfSA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd9848d2-5c7a-45f5-8b93-87b53ccf754d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 2s 95ms/step - loss: 0.4152 - accuracy: 0.9176\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.41517049074172974, 0.9176136255264282]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_at = 100\n",
        "\n",
        "for layer in pretrained_model.layers[fine_tune_at:]:\n",
        "  layer.trainable=True"
      ],
      "metadata": {
        "id": "sqhw3oifWzkQ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.optimizer.learning_rate.assign(model.optimizer.learning_rate / 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dx0WVqYHWXE",
        "outputId": "f73e7f1f-0e46-4145-c814-b94437af4ca4"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.00012499999>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_fine = model.fit(train_set,validation_data=(validation_set),epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn2XbJmYXA1b",
        "outputId": "3559a962-6f22-4247-bf71-13fa59083dc1"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "219/219 [==============================] - 25s 111ms/step - loss: 0.1177 - accuracy: 0.9582 - val_loss: 0.2782 - val_accuracy: 0.9291\n",
            "Epoch 2/10\n",
            "219/219 [==============================] - 25s 111ms/step - loss: 0.1098 - accuracy: 0.9591 - val_loss: 0.2512 - val_accuracy: 0.9327\n",
            "Epoch 3/10\n",
            "219/219 [==============================] - 25s 111ms/step - loss: 0.0975 - accuracy: 0.9628 - val_loss: 0.2851 - val_accuracy: 0.9284\n",
            "Epoch 4/10\n",
            "219/219 [==============================] - 25s 110ms/step - loss: 0.0938 - accuracy: 0.9658 - val_loss: 0.3024 - val_accuracy: 0.9305\n",
            "Epoch 5/10\n",
            "219/219 [==============================] - 25s 111ms/step - loss: 0.0855 - accuracy: 0.9653 - val_loss: 0.2823 - val_accuracy: 0.9362\n",
            "Epoch 6/10\n",
            "219/219 [==============================] - 33s 144ms/step - loss: 0.0869 - accuracy: 0.9663 - val_loss: 0.2460 - val_accuracy: 0.9384\n",
            "Epoch 7/10\n",
            "219/219 [==============================] - 25s 110ms/step - loss: 0.0858 - accuracy: 0.9651 - val_loss: 0.3104 - val_accuracy: 0.9291\n",
            "Epoch 8/10\n",
            "219/219 [==============================] - 25s 110ms/step - loss: 0.0818 - accuracy: 0.9678 - val_loss: 0.3025 - val_accuracy: 0.9341\n",
            "Epoch 9/10\n",
            "219/219 [==============================] - 25s 110ms/step - loss: 0.0846 - accuracy: 0.9664 - val_loss: 0.3057 - val_accuracy: 0.9312\n",
            "Epoch 10/10\n",
            "219/219 [==============================] - 25s 112ms/step - loss: 0.0841 - accuracy: 0.9647 - val_loss: 0.2988 - val_accuracy: 0.9334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLdKa3odKeR4",
        "outputId": "4ee60d07-2047-48fa-d1c0-d8cb48aa55d8"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 2s 94ms/step - loss: 0.4609 - accuracy: 0.9347\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4608772397041321, 0.9346590638160706]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "Paintings_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}